# train ae or vae
#### a template for pcd encoder
mode: train
model:
  # can be AE, VAE, SeM and DDPM
  name: EDM
  eps_model:
    time_channel: 128
    encoder:
      name: SeqNet
      in_channel: 3
      point_num: 256
      building_block: res_dense
      # num_neighbors_k: 20
      seq_feature_channels: [512, 512, 512, 512, 512, 512]
      # num_heads: 8
      # d_k: 64
      voxel_resolutions: [0, 0, 16, 16, 0, 0]
      activation: gelu
      normalization: layer
      channel_attention: eca
      # name: PointTrans
      # in_channel: 3
      # point_num: 256
      # building_block: dense
      # # num_neighbors_k: 20
      # local_feature_channels: [512, 512, 512, 512, 512, 512]
      # dense_channels: [512]
      # activation: gelu
      # normalization: layer
      # channel_attention: eca
      # vector_embedding: false
    condition_embedding:
      combine_condition: injection
      condition_injection: bias
      encoder:
        name: OneHot
        type: categories
        out_channel: 128
        num_classes: 2
      decoder: same_as_encoder
  eps_loss:
    name: MSE
loader:
  dataset: 
    name: PcdClsDataset
    cls_label: imagecas
    data_suffix: ply
  data_path_list: 
    - /media/wlsdzyzl/DATA1/vcg-results/skeleton/imagecas_surface/sknet/skeleton
  batch_size: 2
  num_workers: 8
  shuffle: true
  data_transforms:
    - name: ToTensor
  label_transforms:
    - name: Relabel
      offset: -1
    - name: ToOneHot
      num_classes: 2
    - name: ToTensor
check_point_dir: /media/wlsdzyzl/DATA1/flemme-ckp/imagecas_surface/SeqNet_EDM_Skeleton
### parameter for optimizer
optimizer:
  name: Adam
  lr: 0.001
  weight_decay: 0.00000001
### scheduler for learning rate
lr_scheduler: 
  name: LinearLR
  start_factor: 1.0
  end_factor: 0.01
sampler:
  name: NormalSampler
max_epoch: 1000
write_after_iters: 10
write_sample_num: 4
save_after_epochs: 10
warmup_epochs: 1
warmup_start_scale: 0.01
clip_grad: 1.0