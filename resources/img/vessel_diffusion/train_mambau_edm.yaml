# train ae or vae
model:
  # can be AE, VAE and DDPM
  name: EDM
  eps_model:
    # encoder config
    time_channel: 128
    encoder:
      name: VMambaU
      image_size: [336, 336]
      in_channel: 1
      out_channel: 1
      patch_channel: 32
      patch_size: 2
      # kernel_size: 5
      down_channels: [64, 128, 256]
      middle_channels: [512, 512]
      ### with time embedding
      building_block: vmamba
      activation: silu
      num_blocks: 2
      normalization: group
      num_norm_groups: 16
      dropout: 0.1
  eps_loss:
    name: MSE
split_files:
  train:
    - /data/guoqingzhang/datasets/CoW_vessel_diffusion/split_txt/train.txt
    - /data/guoqingzhang/datasets/CoW_vessel_diffusion/split_txt/val.txt
loader:
  dataset: 
    name: ImgDataset
    data_dir: .
    data_suffix: .png
  data_path_list: 
    - /data/guoqingzhang/datasets/CoW_vessel_diffusion/same_mip_all
  batch_size: 10
  num_workers: 8
  shuffle: true
  data_transforms:
    - name: ToTensor
    - name: Normalize
      mean: [0.5]
      std: [0.5]
check_point_dir: /data/guoqingzhang/flemme-ckp/CoW_vessel_diffusion_mip/EDM_mambau
sampler:
  rand_seed: 2025
### parameter for optimizer
optimizer:
  name: AdamW
  lr: 0.0003
  weight_decay: 0.00000001
### scheduler for learning rate
lr_scheduler: 
  name: LinearLR
  start_factor: 1.0
  end_factor: 0.01
max_epoch: 1000
write_after_iters: 50
save_after_epochs: 5